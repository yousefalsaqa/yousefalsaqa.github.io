<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AutoDrive Lane Detection | Yousef Alsaqa</title>
  <meta name="description" content="Case study: Ultra-fast lane detection for Queen's AutoDrive Level 4 autonomous vehicle.">
  <meta name="theme-color" content="#050508">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Instrument+Sans:wght@400;500;600;700&family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">

  <!-- Bootstrap Icons -->
  <link href="vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">

  <!-- Stylesheets -->
  <link href="css/theme.css" rel="stylesheet">
  <link href="css/pages/case-study.css" rel="stylesheet">
</head>

<body>
  <!-- Header -->
  <header class="header" id="header">
    <div class="header-inner">
      <a href="index.html" class="header-logo">Yousef<span>.</span></a>
      <nav class="header-nav" id="nav">
        <a href="index.html" class="nav-link">Home</a>
        <a href="projects.html" class="nav-link">Projects</a>
        <a href="experience.html" class="nav-link">Experience</a>
        <a href="mailto:21ymsa@queensu.ca" class="nav-link">Contact</a>
      </nav>
      <button class="nav-toggle" id="navToggle" aria-label="Toggle navigation">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
  </header>

  <main>
    <!-- Hero -->
    <section class="case-hero">
      <div class="container">
        <a href="projects.html" class="back-link">
          <i class="bi bi-arrow-left"></i>
          Back to projects
        </a>
        <h1>AutoDrive Lane Detection</h1>
        <p class="subtitle">Implementing Ultra-Fast Lane Detection for a Level 4 autonomous vehicle. 300+ FPS inference on embedded hardware, reliable in rain, shadows, and night driving.</p>
        
        <div class="case-meta">
          <div class="case-meta-item">
            <span class="case-meta-label">Role</span>
            <span class="case-meta-value">Perception Developer</span>
          </div>
          <div class="case-meta-item">
            <span class="case-meta-label">Timeline</span>
            <span class="case-meta-value">Jan 2023 — Aug 2023</span> <!-- [VERIFY DATES] -->
          </div>
          <div class="case-meta-item">
            <span class="case-meta-label">Team</span>
            <span class="case-meta-value">Queen's AutoDrive</span>
          </div>
          <div class="case-meta-item">
            <span class="case-meta-label">Status</span>
            <span class="case-meta-value">Deployed</span>
          </div>
        </div>
      </div>
    </section>

    <!-- Content -->
    <section class="section">
      <div class="container case-content">
        
        <div class="case-section">
          <h2>The Challenge</h2>
          <p>Queen's AutoDrive is building a Level 4 autonomous vehicle for the SAE AutoDrive Challenge. Level 4 means the car drives itself in defined conditions — no human backup required. Lane detection is critical: the car needs to know where the road is, constantly.</p>
          <p>Traditional approaches use pixel-by-pixel segmentation. They're accurate but slow — maybe 30fps on a powerful GPU. We needed something that could run at high framerates on embedded hardware while maintaining accuracy in challenging conditions.</p>
        </div>

        <div class="case-section">
          <h2>The Solution: UFLD</h2>
          <p>I implemented Ultra-Fast Lane Detection (UFLD), a model that reformulates lane detection as a row-based classification problem instead of pixel segmentation.</p>
          
          <h3>How It Works</h3>
          <p>Instead of classifying every pixel, UFLD divides each row of the image into grid cells and predicts which cell contains the lane. This reduces the problem from millions of pixel classifications to thousands of row classifications.</p>
          
          <div class="case-code">
<pre>
# Traditional segmentation: O(H × W × C) per frame
# UFLD: O(H × G × L) per frame
# Where G = grid cells (~200), L = lanes (typically 4)
# 10-100x fewer predictions needed

def process_lanes(image):
    # Resize to model input (288 x 800)
    resized = cv2.resize(image, (800, 288))
    
    # Run inference
    predictions = model(resized)  # Shape: [num_rows, grid_cells, lanes]
    
    # Decode row-wise predictions to lane coordinates
    lanes = decode_predictions(predictions)
    
    return lanes
</pre>
          </div>

          <h3>Model Architecture</h3>
          <p>The backbone is a lightweight ResNet-18, chosen for speed over accuracy. The classification head outputs probabilities for each grid cell in each row. Lane coordinates are extracted by finding the maximum probability cell per row, then fitting a polynomial.</p>
        </div>

        <figure class="case-image">
          <video autoplay loop muted playsinline style="width: 100%; border-radius: 8px;">
            <source src="assets/KingstonLaneDetection.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <figcaption>Lane detection running in real-time on Kingston roads</figcaption>
        </figure>

        <div class="case-section">
          <h2>Technical Challenges</h2>
          
          <h3>Edge Cases</h3>
          <p>Lane detection sounds simple until you encounter:</p>
          <ul>
            <li><strong>Worn lane markings:</strong> Faded or partially obscured lines</li>
            <li><strong>Construction zones:</strong> Temporary yellow lines conflicting with permanent white</li>
            <li><strong>Shadows:</strong> Tree shadows creating false edges</li>
            <li><strong>Weather:</strong> Rain reflections, snow covering lines</li>
            <li><strong>Night driving:</strong> Limited visibility, headlight glare</li>
          </ul>
          
          <p>We augmented the training data heavily — random brightness, contrast, shadows, rain effects. The model learned to look for lane structure, not just white pixels.</p>

          <h3>Embedded Deployment</h3>
          <p>The vehicle uses an NVIDIA Jetson AGX Xavier. I optimized the model using TensorRT:</p>
          
          <div class="tech-grid">
            <div class="tech-item">
              <h4>FP16 Quantization</h4>
              <p>Half precision reduces memory bandwidth with minimal accuracy loss</p>
            </div>
            <div class="tech-item">
              <h4>Layer Fusion</h4>
              <p>TensorRT combines consecutive operations into single kernels</p>
            </div>
            <div class="tech-item">
              <h4>Batch Processing</h4>
              <p>Process multiple cameras simultaneously when possible</p>
            </div>
            <div class="tech-item">
              <h4>CUDA Streams</h4>
              <p>Overlap preprocessing, inference, and postprocessing</p>
            </div>
          </div>

          <h3>Temporal Consistency</h3>
          <p>Raw frame-by-frame predictions can be jittery. I added a Kalman filter to smooth lane positions over time. The filter predicts where lanes should be based on vehicle motion, then corrects with the detected positions.</p>
        </div>

        <div class="case-section">
          <h2>Integration</h2>
          <p>Lane detection feeds into the path planning system. The detected lanes define the drivable corridor, which the planner uses along with obstacle detection to generate trajectories.</p>
          
          <h3>ROS2 Node</h3>
          <p>The lane detector runs as a ROS2 node, publishing lane polynomial coefficients at 30Hz. The message format includes confidence scores so downstream systems can weight the information appropriately.</p>

          <div class="case-code">
<pre>
# Lane message structure
lane_msg:
  header: timestamp + frame_id
  lanes:
    - id: 0 (left lane)
      coefficients: [a0, a1, a2, a3]  # 3rd order polynomial
      confidence: 0.95
      start_y: 0.3  # normalized image coords
      end_y: 0.9
    - id: 1 (right lane)
      ...
</pre>
          </div>
        </div>

        <div class="case-section">
          <h2>Results</h2>
          
          <div class="results-grid">
            <div class="result-item">
              <span class="result-number">300+</span> <!-- [YOUR ACTUAL FPS] -->
              <span class="result-label">FPS on Jetson Xavier</span>
            </div>
            <div class="result-item">
              <span class="result-number">95%</span> <!-- [YOUR ACTUAL ACCURACY] -->
              <span class="result-label">Detection accuracy</span>
            </div>
            <div class="result-item">
              <span class="result-number">3.3ms</span> <!-- [YOUR ACTUAL LATENCY] -->
              <span class="result-label">Inference latency</span>
            </div>
            <div class="result-item">
              <span class="result-number">4</span> <!-- [VERIFY THIS] -->
              <span class="result-label">Simultaneous lanes</span>
            </div>
          </div>

          <p>The lane detection system has been running reliably in the test vehicle. It's a core component of the perception stack and has handled everything from sunny highways to rainy city streets.</p> <!-- [VERIFY/UPDATE THIS DESCRIPTION] -->
        </div>

        <div class="case-section">
          <h2>What I Learned</h2>
          <ul>
            <li><strong>Speed vs. accuracy is a real tradeoff.</strong> For real-time systems, a fast model that's 95% accurate beats a slow model that's 99% accurate. You can handle the 5% with temporal filtering.</li>
            <li><strong>Training data is everything.</strong> The model is only as good as its training set. Heavy augmentation and real-world data collection made more difference than architecture changes.</li>
            <li><strong>Embedded constraints change the game.</strong> Algorithms that work on desktop GPUs often need fundamental rethinking for edge deployment.</li>
          </ul>
        </div>

        <nav class="case-nav">
          <a href="steering-project.html">
            <i class="bi bi-arrow-left"></i>
            Formula SAE Steering
          </a>
          <a href="eii-project-details.html">
            Next: Energy Intensity Predictor
            <i class="bi bi-arrow-right"></i>
          </a>
        </nav>
      </div>
    </section>
  </main>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="footer-content">
        <div class="footer-main">
          <h2>Let's talk.</h2>
          <p>I'm looking for full-time opportunities in robotics, automation, or anywhere I can build things that matter.</p>
          <a href="mailto:21ymsa@queensu.ca" class="footer-email">
            <i class="bi bi-envelope"></i>
            21ymsa@queensu.ca
          </a>
        </div>
        <div class="footer-links">
          <a href="https://www.linkedin.com/in/yousef-alsaqa-b1ab4822b/" target="_blank">
            <i class="bi bi-linkedin"></i>
            LinkedIn
          </a>
          <a href="https://github.com/yousefalsaqa" target="_blank">
            <i class="bi bi-github"></i>
            GitHub
          </a>
          <a href="assets/Yousef_Alsaqa_Resume.pdf" target="_blank">
            <i class="bi bi-file-earmark-text"></i>
            Resume
          </a>
        </div>
      </div>
      <div class="footer-bottom">
        <p>© 2025 Yousef Alsaqa</p>
      </div>
    </div>
  </footer>

  <!-- Scripts -->
  <script>
    const navToggle = document.getElementById('navToggle');
    const nav = document.getElementById('nav');
    
    navToggle.addEventListener('click', () => {
      nav.classList.toggle('active');
      navToggle.classList.toggle('active');
    });

    const header = document.getElementById('header');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 50) {
        header.classList.add('scrolled');
      } else {
        header.classList.remove('scrolled');
      }
    });
  </script>
</body>
</html>
